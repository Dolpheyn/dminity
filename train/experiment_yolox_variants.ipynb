{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "experiment-yolox-variants",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xru6s6p6A18s"
      },
      "source": [
        "# How to Train YOLOX on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOX repository](https://github.com/Megvii-BaseDetection/YOLOX) by [the Megvii Team](https://github.com/Megvii-BaseDetection). This notebook shows training on **your own custom objects**. Many thanks to the Megvii Team for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOX](blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data. We will use Roboflow to preprocess our images.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOX dependencies\n",
        "* Download and Prepare custom YOLOX object detection data\n",
        "* Download Pre-Trained Weights for YOLOX\n",
        "* Run YOLOX training\n",
        "* Evaluate YOLOX performance\n",
        "* Run YOLOX inference on test images\n",
        "* Export saved YOLOX weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVlxlYYBR6z"
      },
      "source": [
        "# Install YOLOX Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igwruhYxE_a7"
      },
      "source": [
        "!git clone https://github.com/roboflow-ai/YOLOX.git\n",
        "%cd YOLOX\n",
        "!pip3 install -U pip && pip3 install -r requirements.txt\n",
        "!pip3 install -v -e .  \n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "# May need to change in the future if Colab no longer uses CUDA 11.0\n",
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llsu3xhVBZYC"
      },
      "source": [
        "## Install Nvidia Apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksHd57LFFMzK"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-EidleBfeB"
      },
      "source": [
        "## Install PyCocoTools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwuWoBOxFV6v"
      },
      "source": [
        "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdiT0rJBmRA"
      },
      "source": [
        "# Download your Data\n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**Pascal VOC**\" export format.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1L8zdwGo_j"
      },
      "source": [
        "%cd /content/\n",
        "!curl -L \"https://app.roboflow.com/ds/<dataset_id>\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "\n",
        "%cd YOLOX/\n",
        "!ln -s /content/train/ ./datasets/VOCdevkit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZSFjXLByrv"
      },
      "source": [
        "## Format Your Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xTRtDWrIw_D"
      },
      "source": [
        "%mkdir -p \"/content/YOLOX/datasets/VOCdevkit/VOC2007\"\n",
        "!python3 voc_txt.py \"/content/YOLOX/datasets/VOCdevkit/\"\n",
        "%mkdir -p \"/content/YOLOX/datasets/VOCdevkit/VOC2012\"\n",
        "!cp -r \"/content/YOLOX/datasets/VOCdevkit/VOC2007/.\" \"/content/YOLOX/datasets/VOCdevkit/VOC2012\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW8iyuMyB3bc"
      },
      "source": [
        "## Change the Classes\n",
        "Make sure you change the classes based on what your dataset. To ensure that the training process will function as intended, write the classes in lowercase with no whitespace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rohuAE541Nug"
      },
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5PM8Ft1OjG"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\n",
        "\n",
        "VOC_CLASSES = (\n",
        "  \"bathtub\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6_LzErQRSU"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\n",
        "\n",
        "COCO_CLASSES = (\n",
        "  \"bathtub\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uAaf5AKSE_E"
      },
      "source": [
        "Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxA0JmWqwU_M"
      },
      "source": [
        "NUM_CLASSES = 30\n",
        "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYvw_GGKaro"
      },
      "source": [
        "# Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsOCh9hRKbIw"
      },
      "source": [
        "%cd /content/\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_m.pth\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_x.pth\n",
        "%cd /content/YOLOX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TabCpJOCRti"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1J2AWY-4lj2"
      },
      "source": [
        "Copy yolox_m and yolox_x into the yolox_voc/ directory. You have to manually copy the dataloader related code from yolox_voc_s.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUuOaP3u5AE"
      },
      "source": [
        "!cp exps/default/yolox_m.py exps/example/yolox_voc/yolox_voc_m.py\n",
        "!cp exps/default/yolox_x.py exps/example/yolox_voc/yolox_voc_x.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5h536amH32Z"
      },
      "source": [
        "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_m.py -d 1 -b 16 --fp16 -o -c /content/yolox_m.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjsuFDICVov"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE5oWuEOICAF"
      },
      "source": [
        "MODEL_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_m/latest_ckpt.pth.tar\"\n",
        "!python3 tools/eval.py -n  yolox-s -c {MODEL_PATH} -b 64 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_m.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnFRJEa7CaPe"
      },
      "source": [
        "# Test the Model\n",
        "Make sure you replace the `TEST_IMAGE_PATH` variable with a test image from your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIXoCCwkMjpK"
      },
      "source": [
        "TEST_IMAGE_PATH = \"/content/valid/11dcac4ca5923a58_jpg.rf.98b83c15ada60eeac517338e92cca441.jpg\"\n",
        "!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_m.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7nX2nwWCper"
      },
      "source": [
        "# Visualize the Predictions\n",
        "Make sure you replace the `OUTPUT_IMAGE_PATH` with the respective path of the image output. This path can be found somewhere in the `YOLOX_outputs` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3_kOK2cZtJK"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_m/vis_res/2021_08_31_01_22_38/11dcac4ca5923a58_jpg.rf.98b83c15ada60eeac517338e92cca441.jpg\"\n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbMKDkxPWoD"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlZf3KlMPYPS",
        "outputId": "815982e7-6328-4be9-9794-ff5599713881"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrqgjePPaXK"
      },
      "source": [
        "%cp {MODEL_PATH} /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5N3Xq2bfcTP"
      },
      "source": [
        "# Watch Experiment in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl-n0IsCmqIn"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PljSm6BIfZbJ"
      },
      "source": [
        "%tensorboard --logdir=/content/YOLOX/YOLOX_outputs/yolox_voc_s/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQELubtjm0nc"
      },
      "source": [
        "# Download Experiment Outputs to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8joee_xm4ML",
        "outputId": "20165900-1362-44c8-9c0d-7924f6a1ac70"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk4thRR1nSrj",
        "outputId": "5ce3a3d2-3ce6-4ce0-a049-a0bb8178908a"
      },
      "source": [
        "EXPERIMENT_NAME = \"\"\n",
        "!zip -r /content/{EXPERIMENT_NAME}.zip /content/YOLOX/YOLOX_outputs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/YOLOX/YOLOX_outputs\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/YOLOX_outputs_baththub.zip . -i /content/YOLOX/YOLOX_outputs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLSTzh46n90h",
        "outputId": "7dfe9979-6ad4-4bae-f7ee-3a8f0d94d1d6"
      },
      "source": [
        "!du -h /content/{EXPERIMENT_NAME}.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "730M\t/content/YOLOX_outputs_baththub.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LE4WaasoEB1"
      },
      "source": [
        "!cp /content/{EXPERIMENT_NAME}.zip /content/gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}